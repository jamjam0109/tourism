{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "from konlpy.utils import pprint \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name에서 관광지명을 가져온다.\n",
    "def get_site_name(file_name):\n",
    "    remove_space = file_name.replace(' ', '')\n",
    "    output = remove_space.split('.')[1].split('_')[0]\n",
    "    return output\n",
    "\n",
    "# file_name에서 '모수부족' file_name과 topkeyword 문구가 없는 file_name을 제거한다.\n",
    "def get_file_name(file_names):\n",
    "    for file_name in file_names:\n",
    "        if '모수부족' in file_name:\n",
    "            file_names.remove(file_name)\n",
    "        elif 'topkeyword' not in file_name:\n",
    "            file_names.remove(file_name)\n",
    "                        \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. 강릉커피거리_topkeyword.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "path: data가 저장되어 있는 경로\n",
    "'''\n",
    "\n",
    "path = './data'\n",
    "\n",
    "file_names = get_file_name(os.listdir(path))\n",
    "\n",
    "first_dict = dict()\n",
    "smaple_output = defaultdict(list)\n",
    "\n",
    "\n",
    "for file_name in file_names:\n",
    "\n",
    "    # 관광지명 가져오기\n",
    "    site_name = get_site_name(file_name)\n",
    "\n",
    "    # 관광지명에 괄호가 존재할 경우 괄호 앞에 부분을 관광지명으로 정의\n",
    "    if '(' in site_name:\n",
    "        site_name = site_name.split('(')[0]\n",
    "\n",
    "    if '[' in site_name:\n",
    "        site_name = site_name.split('[')[0]\n",
    "\n",
    "    if 'csv' in file_name:\n",
    "        df = pd.read_csv(f'{path}/{file_name}', encoding='cp949')\n",
    "\n",
    "    # 데이터분할 파일을 xlsx 형태\n",
    "    if 'xlsx' in file_name:\n",
    "        df = pd.read_excel(f'{path}/{file_name}', sheet_name=0, skiprows = 3)\n",
    "\n",
    "    # 연관어 가져오기 \n",
    "    keyword_freq = df[['key', 'freq']]\n",
    "    \n",
    "    # 연관어에서 관광지 명 삭제\n",
    "    keyword_freq_filter = keyword_freq[keyword_freq.key != site_name]\n",
    "    keyword_freq_filter = keyword_freq_filter[keyword_freq_filter['key'].notnull()]\n",
    "\n",
    "    get_dict = keyword_freq_filter.set_index('key')['freq'].to_dict()\n",
    "    \n",
    "    for k, v in chain(first_dict.items(), get_dict.items()):\n",
    "        smaple_output[k].append(v)\n",
    "        \n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_by_sum = dict()\n",
    "# a = smaple_output.items()\n",
    "\n",
    "# for k, v in a:\n",
    "#     group_by_sum[k] = sum(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mr-doosun.tistory.com/22\n",
    "# https://github.com/koshort/pyeunjeon \n",
    "from konlpy.tag import  Kkma, Okt, Hannanum, Komoran\n",
    "from eunjeon import Mecab\n",
    "\n",
    "kkma = Kkma() # 서울대 개발\n",
    "okt = Okt() # 이전 트위터\n",
    "han = Hannanum() # 카이스트 개발\n",
    "komoran = Komoran() # Shineware 개발\n",
    "mecab = Mecab() # ! pip install eunjeon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본:추운지도\n",
      "Hannanum -> []\n",
      "komoran -> []\n",
      "okt -> []\n",
      "mecab -> ['지도']\n",
      "====================\n",
      "원본:싱그러움이\n",
      "Hannanum -> []\n",
      "komoran -> []\n",
      "okt -> ['움']\n",
      "mecab -> []\n",
      "====================\n",
      "원본:철썩철썩\n",
      "Hannanum -> []\n",
      "komoran -> []\n",
      "okt -> ['철썩', '철썩']\n",
      "mecab -> []\n",
      "====================\n",
      "원본:보내기\n",
      "Hannanum -> []\n",
      "komoran -> []\n",
      "okt -> []\n",
      "mecab -> []\n",
      "====================\n",
      "원본:여기저기\n",
      "Hannanum -> []\n",
      "komoran -> ['여기저기']\n",
      "okt -> ['여기저기']\n",
      "mecab -> ['여기저기']\n",
      "====================\n",
      "원본:서울대입구요가\n",
      "Hannanum -> ['서울대입구요']\n",
      "komoran -> ['서울대', '입구', '요가']\n",
      "okt -> ['서울대', '입구', '요가']\n",
      "mecab -> ['서울대', '입구', '요가']\n",
      "====================\n",
      "원본:여행이었으\n",
      "Hannanum -> ['여행이었으']\n",
      "komoran -> ['여행', '으']\n",
      "okt -> ['여행']\n",
      "mecab -> ['여행']\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "a = ['추운지도', '싱그러움이', '철썩철썩', '보내기', '여기저기', '서울대입구요가', '여행이었으']\n",
    "\n",
    "for key in a:\n",
    "    print('원본:'+key)\n",
    "    print('Hannanum'+' -> '+str(han.nouns(key)))\n",
    "    print('komoran'+' -> '+str(komoran.nouns(key)))\n",
    "    print('okt'+' -> '+str(okt.nouns(key)))    \n",
    "    print('mecab'+' -> '+str(mecab.nouns(key)))    \n",
    "    print('='*20)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = keyword_freq_filter['key'].tolist()\n",
    "\n",
    "li = list()\n",
    "for key in a:\n",
    "    temp_list = list()\n",
    "    temp_list.append(key)\n",
    "    try:\n",
    "        xx = han.nouns(key)\n",
    "    except: \n",
    "        print(key)\n",
    "    if len(xx) == 0:\n",
    "        temp_list.append(' ')\n",
    "    else:\n",
    "        temp_list.append(xx[0])\n",
    "\n",
    "    li.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(li).to_csv('dddd.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
